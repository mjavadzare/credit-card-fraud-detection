import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


df = pd.read_csv('../data/raw/creditcard.csv')





from sklearn.preprocessing import (
    StandardScaler,
    MinMaxScaler,
    FunctionTransformer,
    QuantileTransformer
)
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics.pairwise import rbf_kernel
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import QuantileTransformer
from sklearn.decomposition import PCA


default_pipeline = make_pipeline(
    SimpleImputer(strategy='median'),
    StandardScaler(),
)

Time_rbf_transformer = FunctionTransformer(
    rbf_kernel,
    feature_names_out='one-to-one',
    kw_args={
        'Y':[[79000]],
        'gamma':1e-8
    }
)

q_heavy_tail_pipeline = make_pipeline(
    QuantileTransformer(output_distribution='normal'),
    StandardScaler()
)

# V2, V5, V7 with Amount
V2_amount_pipeline = make_pipeline(
    StandardScaler(),
    PCA(n_components=2)
)

V5_amount_pipeline = make_pipeline(
    StandardScaler(),
    PCA(n_components=2)
)

V7_amount_pipeline = make_pipeline(
    StandardScaler(),
    PCA(n_components=2)
)


all_transformation = ColumnTransformer(
    transformers=[
        ('Time_rbf', Time_rbf_transformer, ['Time']),
        ('heavy_tail', q_heavy_tail_pipeline, ['V1', 'V2', 'V3', 'V4', 'V5',
                                               'V6','V7', 'V8', 'V9', 'V10',
                                               'V11', 'V12', 'V14', 'V15',
                                               'V16', 'V17', 'V18', 'V19', 'V20',
                                               'V21', 'V22', 'V23', 'V24', 'V25',
                                               'V27', 'V28', 'Amount']),
        ('V2_amount', V2_amount_pipeline, ['V2', 'Amount']),
        ('V5_amount', V5_amount_pipeline, ['V5', 'Amount']),
        ('V7_amount', V7_amount_pipeline, ['V7', 'Amount'])
        
    ],
    remainder=default_pipeline,
)


from sklearn.model_selection import train_test_split


train, test = train_test_split(df,
                               test_size=0.2,
                               stratify=df['Class'],
                               random_state=10
                               )


X_train, X_test = train.drop('Class', axis=1), test.drop('Class', axis=1)
y_train, y_test = train['Class'], test['Class']





from sklearn.linear_model import LogisticRegression


lr_pipeline = Pipeline([
    ('transformation', all_transformation),
    ('logistic_r', LogisticRegression(
            class_weight='balanced',
            random_state=10,
            max_iter=1000,
            n_jobs=-1)
    )
])


from sklearn.model_selection import GridSearchCV

param_grid = [
    {
        'transformation__Time_rbf__kw_args': [{'Y': [[79000]],
                                               'gamma': 1e-8}], # this gamma is optimized
        'logistic_r__solver': ['saga'],
        'logistic_r__penalty': ['l1', 'l2']
    },
    {
        'transformation__Time_rbf__kw_args': [{'Y': [[79000]],
                                               'gamma': 1e-8}],
        'logistic_r__solver': ['sag'],
        'logistic_r__penalty': ['l2']
    },
    {
        'transformation__Time_rbf__kw_args': [{'Y': [[79000]],  
                                               'gamma': 1e-8}],
        'logistic_r__solver': ['saga'],
        'logistic_r__penalty': ['elasticnet'],
        'logistic_r__l1_ratio': [0.3, 0.5, 0.8]
    }
]


lr_gs = GridSearchCV(
    estimator=lr_pipeline,
    param_grid=param_grid,
    scoring='neg_mean_absolute_error',
    cv=5
)


lr_gs.fit(X_train, y_train)


lr_gs.best_params_


- lr_gs.best_score_


pd.DataFrame(lr_gs.cv_results_).sort_values(by='mean_test_score', ascending=False)








!pip install lightgbm


import lightgbm
lightgbm.__version__


!pip install imbalanced-learn


from lightgbm import LGBMClassifier
from imblearn.over_sampling import SMOTE



